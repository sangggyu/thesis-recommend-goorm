{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from konlpy.tag import Okt\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b98202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논문 api URL 넣는곳\n",
    "#here\n",
    "\n",
    "def fetch_paper_data(): # 초록, Keywords, abstract\n",
    "    response = requests.get(api_url)\n",
    "    data = response.json()\n",
    "    # 데이터가 딕셔너리 형태로 반환되며, 'title', 'abstract', 'keywords' 키를 포함\n",
    "    return data.get('title', ''), data.get('abstract', ''), data.get('keywords', [])\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = okt.nouns(text)\n",
    "    return tokens\n",
    "\n",
    "# Word2Vec 모델 Skip-gram\n",
    "def train_word2vec_model():\n",
    "    title, abstract, keywords = fetch_paper_data()\n",
    "    df = pd.DataFrame({'text_column': [title + ' ' + abstract + ' ' + ' '.join(keywords)]})\n",
    "    df['processed_text'] = df['text_column'].apply(preprocess_text)\n",
    "    \n",
    "    model = Word2Vec(sentences=df['processed_text'], vector_size=100, window=5, sg=1, min_count=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_document_vector(doc, model):\n",
    "    word_vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    if not word_vectors:\n",
    "        return None\n",
    "    return sum(word_vectors) / len(word_vectors)\n",
    "\n",
    "def find_similar_papers(input_document, model, top_n=10):\n",
    "    input_doc_vector = get_document_vector(preprocess_text(input_document), model)\n",
    "    if input_doc_vector is None:\n",
    "        return None\n",
    "\n",
    "    papers_data = [fetch_paper_data() for _ in range(10)]\n",
    "\n",
    "    similarity_scores = []\n",
    "    for title, abstract, keywords in papers_data:\n",
    "        other_doc_vector = get_document_vector(preprocess_text(title + ' ' + abstract + ' ' + ' '.join(keywords)), model)\n",
    "        if other_doc_vector is not None:\n",
    "            similarity_score = cosine_similarity([input_doc_vector], [other_doc_vector])[0][0]\n",
    "            similarity_scores.append((title, similarity_score))\n",
    "\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    similar_papers = similarity_scores[:min(top_n, len(similarity_scores))]\n",
    "    return similar_papers\n",
    "\n",
    "# test 영역\n",
    "input_text =  \"키워드 입력.\"\n",
    "trained_model = train_word2vec_model()\n",
    "similar_papers = find_similar_papers(input_text, trained_model)\n",
    "\n",
    "print(\"유사한 논문들:\")\n",
    "for title, similarity in similar_papers:\n",
    "    print(f\"유사도 {similarity:.4f}\\nTitle: {title}\\n{'-'*30}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
